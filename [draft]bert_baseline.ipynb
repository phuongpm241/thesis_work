{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful libraries \n",
    "import pickle\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.util as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/data/medg/misc/phuongpm/\" + \"sample1.0.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = u.load_json(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = '../biobert_v1.1_pubmed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = u.JsonDataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = list(data.json_to_plain(remove_notfound=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 = sample_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': ['blood investigations',\n",
       "  'apgar score',\n",
       "  'amniotic band syndrome',\n",
       "  'myriad of deformities of fetal body parts',\n",
       "  'distorted hemicranium',\n",
       "  'adhesions',\n",
       "  'head circumference',\n",
       "  'craniofacial defect',\n",
       "  'vascular disruption sequence',\n",
       "  'minor craniofacial defects',\n",
       "  'saggital suture',\n",
       "  'significant vascular compromise',\n",
       "  'shrivelled amniotic strands ) , ( b ) amniotic adhesions',\n",
       "  'caput succedaneum',\n",
       "  'concavity of the right parietal bone',\n",
       "  'isolated cranial distortion mimicking caput succedenum',\n",
       "  'blood sugar',\n",
       "  'multiple congenital anomalies',\n",
       "  'constrictive tissue bands',\n",
       "  'multiple surgical procedures',\n",
       "  'routine chromosome study',\n",
       "  'syndrome',\n",
       "  'intravenous cefotaxime',\n",
       "  'treatment',\n",
       "  'musculoskeletal and neurological examination of the baby',\n",
       "  'relative preservation on the right side',\n",
       "  'ear abnormality',\n",
       "  'deformation',\n",
       "  'dislocation of craniofacial structures',\n",
       "  'mimicking caput succedaneum',\n",
       "  'distortion',\n",
       "  'antenatal scans',\n",
       "  'fibrous band',\n",
       "  'birth weight',\n",
       "  'moulding of the skull bone over the left parietotemporal region',\n",
       "  'consanguinity',\n",
       "  'overriding or fracture',\n",
       "  'mimic caput succedaneum',\n",
       "  'mimics caput succedaneum',\n",
       "  'subsequent mri scan of the brain',\n",
       "  'lesions',\n",
       "  'similar inbowing of the lateral cranium on the left side',\n",
       "  'skull x-ray',\n",
       "  'significant compromise to satisfactory cosmesis',\n",
       "  'amniotic band disruption syndrome',\n",
       "  'neurological defect',\n",
       "  'vascular',\n",
       "  'prophylactic antibiotics',\n",
       "  'neurological abnormality',\n",
       "  'placental examination',\n",
       "  'other visible congenital anomaly',\n",
       "  'cranial sutures',\n",
       "  'spectrum of defects',\n",
       "  'frontal bossing',\n",
       "  'ultrasound scan',\n",
       "  'craniofacial defects',\n",
       "  'significant medical illness',\n",
       "  'large caput over the left parietal region',\n",
       "  'mild defects in limbs to severe craniofacial defects',\n",
       "  'isolated distortion in the left parietal bone',\n",
       "  'respiratory distress',\n",
       "  'premature rupture',\n",
       "  'cephaloamniotic adhesions',\n",
       "  'depression',\n",
       "  'oxygen saturation',\n",
       "  'nasogastric feeding',\n",
       "  'hypertelorism',\n",
       "  'little - known entity',\n",
       "  'tropin',\n",
       "  'disruption',\n",
       "  'ultrasound scan of the brain',\n",
       "  'chronic illness',\n",
       "  'amniotic band',\n",
       "  'soft tissue swelling',\n",
       "  'audible cardiac murmur',\n",
       "  'concavity in the left parietal bone',\n",
       "  'malformation',\n",
       "  'early amnion rupture',\n",
       "  'swelling',\n",
       "  'amniotic deformities',\n",
       "  'amniotic bands at different stages of organogenesis',\n",
       "  'amniotic band disruption complex',\n",
       "  'clear wide demarcation line',\n",
       "  'subsequent mri',\n",
       "  'amniotic band disruption',\n",
       "  'collection of fluid',\n",
       "  'apparent distortion',\n",
       "  'visceral abnormality',\n",
       "  'visible congenital anomaly',\n",
       "  'circumference of the asymmetric swelling of the scalp'],\n",
       " 'a': 'isolated calvarial deformity mimicking caput succedenum',\n",
       " 'p': 'isolated cranial distortion mimicking caput succedenum from amniotic band disruption without any neurological abnormality summary  this report describes a term newborn with isolated distortion in the left parietal bone without any other visible congenital anomaly , due to amniotic band disruption . a skull x-ray , ultrasound scan and subsequent mri scan of the brain did not show any apparent distortion apart from depression and concavity in the left parietal bone . the purpose of this case report is to raise awareness of this possible , mild outcome of this little - known entity , which may mimic caput succedaneum ( moulding of the presenting part in the birth canal during natural delivery ) , and to provide a historical and embryological background .  background  amniotic band disruption syndrome is a rare entity which occurs in 1 in 1200 to 1 in 15 000 live births . 1 it may cause a myriad of deformities of fetal body parts from mild defects in limbs to severe craniofacial defects incompatible with life . the spectrum of defects includes disruption , deformation and malformation of different body parts due to interference from the amniotic bands at different stages of organogenesis . 2 the syndrome is also described as adam complex ( for ‘ amniotic deformities , adhesions , mutilation ’ ) or amniotic band disruption complex ( abdc ) for its nature of presentation . since tropin described the condition in 1968 , 3 many questions regarding this syndrome remain unanswered because of its rarity and complex mechanism . this case is unique in its presentation as it mimics caput succedaneum without any neurological defect . this type of presentation has not been described before in the medical literature .  case presentation  a girl , born at 38 weeks of gestation by vaginal delivery of normal duration of labour , presented with a large caput over the left parietal region ( figure 1a , b ) . the mother was a 32 - year - old primigravida without any significant medical illness . there was no family history of consanguinity or chronic illness . the pregnancy was uneventful and antenatal scans were reported as normal . the mother had a history of premature rupture of the membrane of more than 24 h and had prophylactic antibiotics . the baby did not cry immediately after birth . the apgar score at 1 min was 5 , and this increased to 9 after five inflation breaths . her blood sugar was 6.1 mmol / litre . her birth weight was 1960 g ( 9th to 25th centile ) and head circumference was 29 cm ( 9th centile ) . she was pink , handling well and moving all her limbs spontaneously . her oxygen saturation on air was 99 % . she did not have any respiratory distress , visible congenital anomaly or audible cardiac murmur . there was no frontal bossing , ear abnormality or hypertelorism . musculoskeletal and neurological examination of the baby was normal . the craniofacial contours of the parents were unremarkable .  the circumference of the asymmetric swelling of the scalp was 26 cm . a clear wide demarcation line was present between the swelling and the vessels of the scalp . the skin over the swelling appeared darker than the rest of the scalp . cranial sutures including the saggital suture could not be felt due to the swelling . the newborn was given nasogastric feeding and intravenous cefotaxime .  investigations  her blood investigations were all within normal limits . a skull x-ray showed moulding of the skull bone over the left parietotemporal region ( figures 2 and 3 ) . no overriding or fracture was found except soft tissue swelling overlying the vertex . an ultrasound scan of the brain showed symmetrical lateral ventricles in both hemispheres with falx at the midline . a collection of fluid of 0.7 – 1 cm in diameter was found over the calvaria , which was suggestive of caput succedaneum .  a subsequent mri showed the left hemicranium was distorted with relative preservation on the right side ( figure 4 ) . there was some concavity of the right parietal bone at the edge of caput succedaneum and similar inbowing of the lateral cranium on the left side , which was suggestive of modelling by an amniotic band .  differential diagnosis  treatment  outcome and follow - up  discussion  though the exact aetiology of abdc is unknown , two main pathogenetic mechanisms are proposed . exogenous theory suggests early amnion rupture leading to a fibrous band that can entrap fetal body part ( figure 5 ) . the endogenous theory suggests vascular compromise . genetic factors might operate in some cases .  moerman et al described three types of lesions in this complex : ( a ) constrictive tissue bands ( shrivelled amniotic strands ) , ( b ) amniotic adhesions ( fusion between disrupted body part and intact amniotic membrane ) and ( c ) limb – body wall complex . 6 according to their observations , most of the craniofacial defects occur as a result of a vascular disruption sequence with or without cephaloamniotic adhesions , unlike the case described here that had the clear mark of a constriction band without significant vascular compromise .  an accurate diagnosis may be achieved by looking for the major features of amniotic band syndrome , and a routine chromosome study and placental examination in cases with multiple congenital anomalies . 27  though encephalocele , clefts , distortion and dislocation of craniofacial structures have been described as presentations of craniofacial defect related to this syndrome in the medical literature , 5 distorted hemicranium ( mimicking caput succedaneum ) without any neurological defect has never been described previously . the outcome of the syndrome depends on the gravity of malformation . termination of pregnancy is considered in cases of severe craniofacial or visceral abnormality . successful limb salvage by fetoscopic release of an amniotic band has been reported . most of the minor craniofacial defects require multiple surgical procedures to restore function , with significant compromise to satisfactory cosmesis .',\n",
       " 'q': '▶ @placeholder from amniotic band disruption is a possibility .',\n",
       " 'id': 'bcr.12.2009.2549.1'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input0['p']\n",
    "#+ input0['q'].replace('▶ @placeholder', '[MASK]') + ' [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1301"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['isolated',\n",
       " 'cr',\n",
       " '##anial',\n",
       " 'distortion',\n",
       " 'mimic',\n",
       " '##king',\n",
       " 'cap',\n",
       " '##ut',\n",
       " 'su',\n",
       " '##cc',\n",
       " '##ede',\n",
       " '##num',\n",
       " 'from',\n",
       " 'am',\n",
       " '##nio',\n",
       " '##tic',\n",
       " 'band',\n",
       " 'disruption',\n",
       " 'without',\n",
       " 'any',\n",
       " 'neurological',\n",
       " 'abnormal',\n",
       " '##ity',\n",
       " 'summary',\n",
       " 'this',\n",
       " 'report',\n",
       " 'describes',\n",
       " 'a',\n",
       " 'term',\n",
       " 'newborn',\n",
       " 'with',\n",
       " 'isolated',\n",
       " 'distortion',\n",
       " 'in',\n",
       " 'the',\n",
       " 'left',\n",
       " 'par',\n",
       " '##ie',\n",
       " '##tal',\n",
       " 'bone',\n",
       " 'without',\n",
       " 'any',\n",
       " 'other',\n",
       " 'visible',\n",
       " 'congenital',\n",
       " 'anomaly',\n",
       " ',',\n",
       " 'due',\n",
       " 'to',\n",
       " 'am',\n",
       " '##nio',\n",
       " '##tic',\n",
       " 'band',\n",
       " 'disruption',\n",
       " '.',\n",
       " 'a',\n",
       " 'skull',\n",
       " 'x',\n",
       " '-',\n",
       " 'ray',\n",
       " ',',\n",
       " 'ultrasound',\n",
       " 'scan',\n",
       " 'and',\n",
       " 'subsequent',\n",
       " 'mri',\n",
       " 'scan',\n",
       " 'of',\n",
       " 'the',\n",
       " 'brain',\n",
       " 'did',\n",
       " 'not',\n",
       " 'show',\n",
       " 'any',\n",
       " 'apparent',\n",
       " 'distortion',\n",
       " 'apart',\n",
       " 'from',\n",
       " 'depression',\n",
       " 'and',\n",
       " 'con',\n",
       " '##ca',\n",
       " '##vity',\n",
       " 'in',\n",
       " 'the',\n",
       " 'left',\n",
       " 'par',\n",
       " '##ie',\n",
       " '##tal',\n",
       " 'bone',\n",
       " '.',\n",
       " 'the',\n",
       " 'purpose',\n",
       " 'of',\n",
       " 'this',\n",
       " 'case',\n",
       " 'report',\n",
       " 'is',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'awareness',\n",
       " 'of',\n",
       " 'this',\n",
       " 'possible',\n",
       " ',',\n",
       " 'mild',\n",
       " 'outcome',\n",
       " 'of',\n",
       " 'this',\n",
       " 'little',\n",
       " '-',\n",
       " 'known',\n",
       " 'entity',\n",
       " ',',\n",
       " 'which',\n",
       " 'may',\n",
       " 'mimic',\n",
       " 'cap',\n",
       " '##ut',\n",
       " 'su',\n",
       " '##cc',\n",
       " '##eda',\n",
       " '##ne',\n",
       " '##um',\n",
       " '(',\n",
       " 'mo',\n",
       " '##uld',\n",
       " '##ing',\n",
       " 'of',\n",
       " 'the',\n",
       " 'presenting',\n",
       " 'part',\n",
       " 'in',\n",
       " 'the',\n",
       " 'birth',\n",
       " 'canal',\n",
       " 'during',\n",
       " 'natural',\n",
       " 'delivery',\n",
       " ')',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'provide',\n",
       " 'a',\n",
       " 'historical',\n",
       " 'and',\n",
       " 'embryo',\n",
       " '##logical',\n",
       " 'background',\n",
       " '.',\n",
       " 'background',\n",
       " 'am',\n",
       " '##nio',\n",
       " '##tic',\n",
       " 'band',\n",
       " 'disruption',\n",
       " 'syndrome',\n",
       " 'is',\n",
       " 'a',\n",
       " 'rare',\n",
       " 'entity',\n",
       " 'which',\n",
       " 'occurs',\n",
       " 'in',\n",
       " '1',\n",
       " 'in',\n",
       " '1200',\n",
       " 'to',\n",
       " '1',\n",
       " 'in',\n",
       " '15',\n",
       " '000',\n",
       " 'live',\n",
       " 'births',\n",
       " '.',\n",
       " '1',\n",
       " 'it',\n",
       " 'may',\n",
       " 'cause',\n",
       " 'a',\n",
       " 'myriad',\n",
       " 'of',\n",
       " 'def',\n",
       " '##or',\n",
       " '##mit',\n",
       " '##ies',\n",
       " 'of',\n",
       " 'fetal',\n",
       " 'body',\n",
       " 'parts',\n",
       " 'from',\n",
       " 'mild',\n",
       " 'defects',\n",
       " 'in',\n",
       " 'limbs',\n",
       " 'to',\n",
       " 'severe',\n",
       " 'cr',\n",
       " '##ani',\n",
       " '##of',\n",
       " '##ac',\n",
       " '##ial',\n",
       " 'defects',\n",
       " 'incompatible',\n",
       " 'with',\n",
       " 'life',\n",
       " '.',\n",
       " 'the',\n",
       " 'spectrum',\n",
       " 'of',\n",
       " 'defects',\n",
       " 'includes',\n",
       " 'disruption',\n",
       " ',',\n",
       " 'deformation',\n",
       " 'and',\n",
       " 'mal',\n",
       " '##form',\n",
       " '##ation',\n",
       " 'of',\n",
       " 'different',\n",
       " 'body',\n",
       " 'parts',\n",
       " 'due',\n",
       " 'to',\n",
       " 'interference',\n",
       " 'from',\n",
       " 'the',\n",
       " 'am',\n",
       " '##nio',\n",
       " '##tic',\n",
       " 'bands',\n",
       " 'at',\n",
       " 'different',\n",
       " 'stages',\n",
       " 'of',\n",
       " 'organ',\n",
       " '##ogen',\n",
       " '##esis',\n",
       " '.',\n",
       " '2',\n",
       " 'the',\n",
       " 'syndrome',\n",
       " 'is',\n",
       " 'also',\n",
       " 'described',\n",
       " 'as',\n",
       " 'adam',\n",
       " 'complex',\n",
       " '(',\n",
       " 'for',\n",
       " '‘',\n",
       " 'am',\n",
       " '##nio',\n",
       " '##tic',\n",
       " 'def',\n",
       " '##or',\n",
       " '##mit',\n",
       " '##ies',\n",
       " ',',\n",
       " 'ad',\n",
       " '##hesion',\n",
       " '##s',\n",
       " ',',\n",
       " 'mu',\n",
       " '##tila',\n",
       " '##tion',\n",
       " '’',\n",
       " ')',\n",
       " 'or',\n",
       " 'am',\n",
       " '##nio',\n",
       " '##tic',\n",
       " 'band',\n",
       " 'disruption',\n",
       " 'complex',\n",
       " '(',\n",
       " 'abd',\n",
       " '##c',\n",
       " ')',\n",
       " 'for',\n",
       " 'its',\n",
       " 'nature',\n",
       " 'of',\n",
       " 'presentation',\n",
       " '.',\n",
       " 'since',\n",
       " 'tr',\n",
       " '##op',\n",
       " '##in',\n",
       " 'described',\n",
       " 'the',\n",
       " 'condition',\n",
       " 'in',\n",
       " '1968',\n",
       " ',',\n",
       " '3',\n",
       " 'many',\n",
       " 'questions',\n",
       " 'regarding',\n",
       " 'this',\n",
       " 'syndrome',\n",
       " 'remain',\n",
       " 'una',\n",
       " '##ns',\n",
       " '##wer',\n",
       " '##ed',\n",
       " 'because',\n",
       " 'of',\n",
       " 'its',\n",
       " 'ra',\n",
       " '##rity',\n",
       " 'and',\n",
       " 'complex',\n",
       " 'mechanism',\n",
       " '.',\n",
       " 'this',\n",
       " 'case',\n",
       " 'is',\n",
       " 'unique',\n",
       " 'in',\n",
       " 'its',\n",
       " 'presentation',\n",
       " 'as',\n",
       " 'it',\n",
       " 'mimic',\n",
       " '##s',\n",
       " 'cap',\n",
       " '##ut',\n",
       " 'su',\n",
       " '##cc',\n",
       " '##eda',\n",
       " '##ne',\n",
       " '##um',\n",
       " 'without',\n",
       " 'any',\n",
       " 'neurological',\n",
       " 'defect',\n",
       " '.',\n",
       " 'this',\n",
       " 'type',\n",
       " 'of',\n",
       " 'presentation',\n",
       " 'has',\n",
       " 'not',\n",
       " 'been',\n",
       " 'described',\n",
       " 'before',\n",
       " 'in',\n",
       " 'the',\n",
       " 'medical',\n",
       " 'literature',\n",
       " '.',\n",
       " 'case',\n",
       " 'presentation',\n",
       " 'a',\n",
       " 'girl',\n",
       " ',',\n",
       " 'born',\n",
       " 'at',\n",
       " '38',\n",
       " 'weeks',\n",
       " 'of',\n",
       " 'ge',\n",
       " '##station',\n",
       " 'by',\n",
       " 'va',\n",
       " '##ginal',\n",
       " 'delivery',\n",
       " 'of',\n",
       " 'normal',\n",
       " 'duration',\n",
       " 'of',\n",
       " 'labour',\n",
       " ',',\n",
       " 'presented',\n",
       " 'with',\n",
       " 'a',\n",
       " 'large',\n",
       " 'cap',\n",
       " '##ut',\n",
       " 'over',\n",
       " 'the',\n",
       " 'left',\n",
       " 'par',\n",
       " '##ie',\n",
       " '##tal',\n",
       " 'region',\n",
       " '(',\n",
       " 'figure',\n",
       " '1a',\n",
       " ',',\n",
       " 'b',\n",
       " ')',\n",
       " '.',\n",
       " 'the',\n",
       " 'mother',\n",
       " 'was',\n",
       " 'a',\n",
       " '32',\n",
       " '-',\n",
       " 'year',\n",
       " '-',\n",
       " 'old',\n",
       " 'pri',\n",
       " '##mi',\n",
       " '##gra',\n",
       " '##vid',\n",
       " '##a',\n",
       " 'without',\n",
       " 'any',\n",
       " 'significant',\n",
       " 'medical',\n",
       " 'illness',\n",
       " '.',\n",
       " 'there',\n",
       " 'was',\n",
       " 'no',\n",
       " 'family',\n",
       " 'history',\n",
       " 'of',\n",
       " 'con',\n",
       " '##san',\n",
       " '##gui',\n",
       " '##nity',\n",
       " 'or',\n",
       " 'chronic',\n",
       " 'illness',\n",
       " '.',\n",
       " 'the',\n",
       " 'pregnancy',\n",
       " 'was',\n",
       " 'uneven',\n",
       " '##tf',\n",
       " '##ul',\n",
       " 'and',\n",
       " 'ant',\n",
       " '##ena',\n",
       " '##tal',\n",
       " 'scans',\n",
       " 'were',\n",
       " 'reported',\n",
       " 'as',\n",
       " 'normal',\n",
       " '.',\n",
       " 'the',\n",
       " 'mother',\n",
       " 'had',\n",
       " 'a',\n",
       " 'history',\n",
       " 'of',\n",
       " 'premature',\n",
       " 'ru',\n",
       " '##pt',\n",
       " '##ure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'membrane',\n",
       " 'of',\n",
       " 'more',\n",
       " 'than',\n",
       " '24',\n",
       " 'h',\n",
       " 'and',\n",
       " 'had',\n",
       " 'prop',\n",
       " '##hyl',\n",
       " '##actic',\n",
       " 'antibiotics',\n",
       " '.',\n",
       " 'the',\n",
       " 'baby',\n",
       " 'did',\n",
       " 'not',\n",
       " 'cry',\n",
       " 'immediately',\n",
       " 'after',\n",
       " 'birth',\n",
       " '.',\n",
       " 'the',\n",
       " 'ap',\n",
       " '##gar',\n",
       " 'score',\n",
       " 'at',\n",
       " '1',\n",
       " 'min',\n",
       " 'was',\n",
       " '5',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'increased',\n",
       " 'to',\n",
       " '9',\n",
       " 'after',\n",
       " 'five',\n",
       " 'inflation',\n",
       " 'breaths',\n",
       " '.',\n",
       " 'her',\n",
       " 'blood',\n",
       " 'sugar',\n",
       " 'was',\n",
       " '6',\n",
       " '.',\n",
       " '1',\n",
       " 'mm',\n",
       " '##ol',\n",
       " '/',\n",
       " 'litre',\n",
       " '.',\n",
       " 'her',\n",
       " 'birth',\n",
       " 'weight',\n",
       " 'was',\n",
       " '1960',\n",
       " 'g',\n",
       " '(',\n",
       " '9th',\n",
       " 'to',\n",
       " '25th',\n",
       " 'cent',\n",
       " '##ile',\n",
       " ')',\n",
       " 'and',\n",
       " 'head',\n",
       " 'ci',\n",
       " '##rc',\n",
       " '##um',\n",
       " '##ference',\n",
       " 'was',\n",
       " '29',\n",
       " 'cm',\n",
       " '(',\n",
       " '9th',\n",
       " 'cent',\n",
       " '##ile',\n",
       " ')',\n",
       " '.',\n",
       " 'she',\n",
       " 'was',\n",
       " 'pink',\n",
       " ',',\n",
       " 'handling',\n",
       " 'well',\n",
       " 'and',\n",
       " 'moving',\n",
       " 'all',\n",
       " 'her',\n",
       " 'limbs',\n",
       " 'spontaneously',\n",
       " '.',\n",
       " 'her',\n",
       " 'oxygen',\n",
       " 'sat',\n",
       " '##uration',\n",
       " 'on',\n",
       " 'air',\n",
       " 'was',\n",
       " '99',\n",
       " '%',\n",
       " '.',\n",
       " 'she',\n",
       " 'did',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'respiratory',\n",
       " 'distress',\n",
       " ',',\n",
       " 'visible',\n",
       " 'congenital',\n",
       " 'anomaly',\n",
       " 'or',\n",
       " 'audible',\n",
       " 'cardiac',\n",
       " 'murmur',\n",
       " '.',\n",
       " 'there',\n",
       " 'was',\n",
       " 'no',\n",
       " 'frontal',\n",
       " 'boss',\n",
       " '##ing',\n",
       " ',',\n",
       " 'ear',\n",
       " 'abnormal',\n",
       " '##ity',\n",
       " 'or',\n",
       " 'hyper',\n",
       " '##tel',\n",
       " '##oris',\n",
       " '##m',\n",
       " '.',\n",
       " 'mu',\n",
       " '##scu',\n",
       " '##los',\n",
       " '##kel',\n",
       " '##eta',\n",
       " '##l',\n",
       " 'and',\n",
       " 'neurological',\n",
       " 'examination',\n",
       " 'of',\n",
       " 'the',\n",
       " 'baby',\n",
       " 'was',\n",
       " 'normal',\n",
       " '.',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##ani',\n",
       " '##of',\n",
       " '##ac',\n",
       " '##ial',\n",
       " 'con',\n",
       " '##tour',\n",
       " '##s',\n",
       " 'of',\n",
       " 'the',\n",
       " 'parents',\n",
       " 'were',\n",
       " 'un',\n",
       " '##rem',\n",
       " '##ark',\n",
       " '##able',\n",
       " '.',\n",
       " 'the',\n",
       " 'ci',\n",
       " '##rc',\n",
       " '##um',\n",
       " '##ference',\n",
       " 'of',\n",
       " 'the',\n",
       " 'as',\n",
       " '##ym',\n",
       " '##metric',\n",
       " 'swelling',\n",
       " 'of',\n",
       " 'the',\n",
       " 'scalp',\n",
       " 'was',\n",
       " '26',\n",
       " 'cm',\n",
       " '.',\n",
       " 'a',\n",
       " 'clear',\n",
       " 'wide',\n",
       " 'dem',\n",
       " '##ar',\n",
       " '##cation',\n",
       " 'line',\n",
       " 'was',\n",
       " 'present',\n",
       " 'between',\n",
       " 'the',\n",
       " 'swelling',\n",
       " 'and',\n",
       " 'the',\n",
       " 'vessels',\n",
       " 'of',\n",
       " 'the',\n",
       " 'scalp',\n",
       " '.',\n",
       " 'the',\n",
       " 'skin',\n",
       " 'over',\n",
       " 'the',\n",
       " 'swelling',\n",
       " 'appeared',\n",
       " 'darker',\n",
       " 'than',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'scalp',\n",
       " '.',\n",
       " 'cr',\n",
       " '##anial',\n",
       " 'su',\n",
       " '##tures',\n",
       " 'including',\n",
       " 'the',\n",
       " 'sa',\n",
       " '##gg',\n",
       " '##ital',\n",
       " 'su',\n",
       " '##ture',\n",
       " 'could',\n",
       " 'not',\n",
       " 'be',\n",
       " 'felt',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'swelling',\n",
       " '.',\n",
       " 'the',\n",
       " 'newborn',\n",
       " 'was',\n",
       " 'given',\n",
       " 'nas',\n",
       " '##oga',\n",
       " '##st',\n",
       " '##ric',\n",
       " 'feeding',\n",
       " 'and',\n",
       " 'intra',\n",
       " '##ven',\n",
       " '##ous',\n",
       " 'ce',\n",
       " '##fo',\n",
       " '##ta',\n",
       " '##xi',\n",
       " '##me',\n",
       " '.',\n",
       " 'investigations',\n",
       " 'her',\n",
       " 'blood',\n",
       " 'investigations',\n",
       " 'were',\n",
       " 'all',\n",
       " 'within',\n",
       " 'normal',\n",
       " 'limits',\n",
       " '.',\n",
       " 'a',\n",
       " 'skull',\n",
       " 'x',\n",
       " '-',\n",
       " 'ray',\n",
       " 'showed',\n",
       " 'mo',\n",
       " '##uld',\n",
       " '##ing',\n",
       " 'of',\n",
       " 'the',\n",
       " 'skull',\n",
       " 'bone',\n",
       " 'over',\n",
       " 'the',\n",
       " 'left',\n",
       " 'par',\n",
       " '##ie',\n",
       " '##to',\n",
       " '##tem',\n",
       " '##por',\n",
       " '##al',\n",
       " 'region',\n",
       " '(',\n",
       " 'figures',\n",
       " '2',\n",
       " 'and',\n",
       " '3',\n",
       " ')',\n",
       " '.',\n",
       " 'no',\n",
       " 'over',\n",
       " '##riding',\n",
       " 'or',\n",
       " 'fracture',\n",
       " 'was',\n",
       " 'found',\n",
       " 'except',\n",
       " 'soft',\n",
       " 'tissue',\n",
       " 'swelling',\n",
       " 'overly',\n",
       " '##ing',\n",
       " 'the',\n",
       " 'vertex',\n",
       " '.',\n",
       " 'an',\n",
       " 'ultrasound',\n",
       " 'scan',\n",
       " 'of',\n",
       " 'the',\n",
       " 'brain',\n",
       " 'showed',\n",
       " 'symmetrical',\n",
       " 'lateral',\n",
       " 'vent',\n",
       " '##ric',\n",
       " '##les',\n",
       " 'in',\n",
       " 'both',\n",
       " 'hemisphere',\n",
       " '##s',\n",
       " 'with',\n",
       " 'fa',\n",
       " '##l',\n",
       " '##x',\n",
       " 'at',\n",
       " 'the',\n",
       " 'mid',\n",
       " '##line',\n",
       " '.',\n",
       " 'a',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'fluid',\n",
       " 'of',\n",
       " '0',\n",
       " '.',\n",
       " '7',\n",
       " '–',\n",
       " '1',\n",
       " 'cm',\n",
       " 'in',\n",
       " 'diameter',\n",
       " 'was',\n",
       " 'found',\n",
       " 'over',\n",
       " 'the',\n",
       " 'cal',\n",
       " '##var',\n",
       " '##ia',\n",
       " ',',\n",
       " 'which',\n",
       " 'was',\n",
       " 'suggest',\n",
       " '##ive',\n",
       " 'of',\n",
       " 'cap',\n",
       " '##ut',\n",
       " 'su',\n",
       " '##cc',\n",
       " '##eda',\n",
       " '##ne',\n",
       " '##um',\n",
       " '.',\n",
       " 'a',\n",
       " 'subsequent',\n",
       " 'mri',\n",
       " 'showed',\n",
       " 'the',\n",
       " 'left',\n",
       " 'hem',\n",
       " '##ic',\n",
       " '##rani',\n",
       " '##um',\n",
       " 'was',\n",
       " 'distorted',\n",
       " 'with',\n",
       " 'relative',\n",
       " 'preservation',\n",
       " 'on',\n",
       " 'the',\n",
       " 'right',\n",
       " 'side',\n",
       " '(',\n",
       " 'figure',\n",
       " '4',\n",
       " ')',\n",
       " '.',\n",
       " 'there',\n",
       " 'was',\n",
       " 'some',\n",
       " 'con',\n",
       " '##ca',\n",
       " '##vity',\n",
       " 'of',\n",
       " 'the',\n",
       " 'right',\n",
       " 'par',\n",
       " '##ie',\n",
       " '##tal',\n",
       " 'bone',\n",
       " 'at',\n",
       " 'the',\n",
       " 'edge',\n",
       " 'of',\n",
       " 'cap',\n",
       " '##ut',\n",
       " 'su',\n",
       " '##cc',\n",
       " '##eda',\n",
       " '##ne',\n",
       " '##um',\n",
       " 'and',\n",
       " 'similar',\n",
       " 'in',\n",
       " '##bow',\n",
       " '##ing',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lateral',\n",
       " 'cr',\n",
       " '##ani',\n",
       " '##um',\n",
       " 'on',\n",
       " 'the',\n",
       " 'left',\n",
       " 'side',\n",
       " ',',\n",
       " 'which',\n",
       " 'was',\n",
       " 'suggest',\n",
       " '##ive',\n",
       " 'of',\n",
       " 'modelling',\n",
       " 'by',\n",
       " 'an',\n",
       " 'am',\n",
       " '##nio',\n",
       " '##tic',\n",
       " 'band',\n",
       " '.',\n",
       " 'differential',\n",
       " 'diagnosis',\n",
       " 'treatment',\n",
       " 'outcome',\n",
       " 'and',\n",
       " 'follow',\n",
       " '-',\n",
       " 'up',\n",
       " 'discussion',\n",
       " 'though',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'ae',\n",
       " '##ti',\n",
       " '##ology',\n",
       " 'of',\n",
       " 'abd',\n",
       " '##c',\n",
       " 'is',\n",
       " 'unknown',\n",
       " ',',\n",
       " 'two',\n",
       " 'main',\n",
       " 'pathogen',\n",
       " '##etic',\n",
       " 'mechanisms',\n",
       " 'are',\n",
       " 'proposed',\n",
       " '.',\n",
       " 'ex',\n",
       " '##ogen',\n",
       " '##ous',\n",
       " 'theory',\n",
       " 'suggests',\n",
       " 'early',\n",
       " 'am',\n",
       " '##nio',\n",
       " '##n',\n",
       " 'ru',\n",
       " '##pt',\n",
       " '##ure',\n",
       " 'leading',\n",
       " 'to',\n",
       " 'a',\n",
       " 'fi',\n",
       " '##bro',\n",
       " '##us',\n",
       " 'band',\n",
       " 'that',\n",
       " 'can',\n",
       " 'en',\n",
       " '##tra',\n",
       " '##p',\n",
       " 'fetal',\n",
       " 'body',\n",
       " 'part',\n",
       " '(',\n",
       " 'figure',\n",
       " '5',\n",
       " ')',\n",
       " '.',\n",
       " 'the',\n",
       " 'end',\n",
       " '##ogen',\n",
       " '##ous',\n",
       " 'theory',\n",
       " 'suggests',\n",
       " 'vascular',\n",
       " 'compromise',\n",
       " '.',\n",
       " 'genetic',\n",
       " 'factors',\n",
       " 'might',\n",
       " 'operate',\n",
       " 'in',\n",
       " 'some',\n",
       " 'cases',\n",
       " '.',\n",
       " 'moe',\n",
       " '##rman',\n",
       " 'et',\n",
       " 'al',\n",
       " 'described',\n",
       " 'three',\n",
       " 'types',\n",
       " 'of',\n",
       " 'lesions',\n",
       " 'in',\n",
       " 'this',\n",
       " 'complex',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_toks = tokenizer.tokenize(input0['q'].replace('@placeholder', '[MASK]') + ' [SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " '[MASK]',\n",
       " 'from',\n",
       " 'am',\n",
       " '##nio',\n",
       " '##tic',\n",
       " 'band',\n",
       " 'disruption',\n",
       " 'is',\n",
       " 'a',\n",
       " 'possibility',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_max_len=tokenizer.max_len - len(query_toks) - 2 #[CLS] and [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexPositions(listOfElements, element):\n",
    "    ''' Returns the indexes of all occurrences of give element in\n",
    "    the list- listOfElements '''\n",
    "    indexPosList = []\n",
    "    indexPos = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # Search for item in list from indexPos to the end of list\n",
    "            indexPos = listOfElements.index(element, indexPos)\n",
    "            # Add the index position in list\n",
    "            indexPosList.append(indexPos)\n",
    "            indexPos += 1\n",
    "        except ValueError as e:\n",
    "            break\n",
    " \n",
    "    return indexPosList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding sentences in the passage\n",
    "index_end_sent = getIndexPositions(tokenized_text, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = ['[CLS]'] + tokenized_text[:480] + ['SEP']\n",
    "sent2 = ['[CLS]'] + tokenized_text[480:971]+ ['SEP']\n",
    "sent3 = ['[CLS]'] + tokenized_text[971:]+ ['SEP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(sent1 + query_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_ids = [0]*len(sent1) + [1]*len(query_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segments_ids) == len(sent1 + query_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_tensor = tokens_tensor.to('cuda')\n",
    "# segments_tensors = segments_tensors.to('cuda')\n",
    "# model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [tokenizer.tokenize(i) for i in input0['c']]\n",
    "candidateids = [tokenizer.convert_tokens_to_ids(i) for i in candidates]\n",
    "flatten_cands = []\n",
    "for i in candidateids:\n",
    "    flatten_cands.extend(i)\n",
    "flatten = set(flatten_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    predictions = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_index = predictions[0, len(sent1) + 1, list(flatten)]\n",
    "# predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5285e+00,  8.3576e-01, -2.3935e+00, -8.1137e-01,  7.6414e+00,\n",
       "         3.8085e-01,  2.9014e+00,  1.5688e+00,  3.5203e+00,  6.3270e+00,\n",
       "         1.8005e+00, -3.9622e+00,  1.6744e+00, -4.7843e+00, -1.0267e+00,\n",
       "         2.5868e+00, -5.8010e+00,  5.2336e-01,  9.5994e-02,  2.2915e+00,\n",
       "        -4.0275e+00, -1.7311e+00,  1.4442e+00, -2.4006e+00, -1.8713e+00,\n",
       "        -5.1228e+00,  1.4464e+00,  1.6116e+00, -2.5458e+00,  1.9800e+00,\n",
       "        -4.4311e+00,  1.1366e+00,  6.7778e-01, -2.5040e+00, -1.6833e+00,\n",
       "        -7.9599e-01, -3.2413e-01,  3.0007e+00, -9.7884e-01,  7.4727e-01,\n",
       "        -2.6176e+00,  8.1412e-01,  1.5103e+00,  7.4303e+00, -4.8734e+00,\n",
       "         1.6225e+00,  1.1380e+00, -4.6375e-01,  4.9648e+00,  8.1434e-01,\n",
       "        -1.1045e+00, -6.2286e+00,  3.8701e+00,  3.4522e-01, -7.7602e-01,\n",
       "         4.7956e+00, -9.7767e-01,  5.1857e+00,  4.7559e+00,  2.0051e+00,\n",
       "        -9.4941e-01, -5.5339e+00, -6.9401e+00, -3.7441e+00, -2.6547e+00,\n",
       "         1.4493e+00, -2.1867e+00, -8.9202e-01,  7.6172e+00, -6.8686e+00,\n",
       "        -1.3658e+00, -8.4137e+00, -8.3380e+00, -1.4908e+00,  1.1896e+00,\n",
       "         1.9463e+00, -2.6426e-01,  1.7258e+00, -3.5529e+00, -1.6577e-01,\n",
       "        -3.5409e-01,  3.3509e+00,  1.2914e+00,  1.0622e+00, -5.5191e-02,\n",
       "        -2.4485e+00, -4.2760e+00, -2.4579e+00, -2.1935e-01,  1.4967e+00,\n",
       "         8.5987e-01,  2.5260e+00, -5.4721e+00,  1.0071e+00,  7.7551e-01,\n",
       "        -3.0010e+00,  8.8647e-01, -7.5122e-01,  1.0535e+00, -4.4108e+00,\n",
       "        -1.3268e+00, -4.9483e+00,  6.8454e+00, -6.6990e+00, -8.5753e-01,\n",
       "        -3.0653e+00, -2.3985e+00,  1.5627e+00,  4.9351e-01, -2.9312e+00,\n",
       "        -3.7205e+00, -1.7422e-01, -2.8159e+00,  4.2073e-04, -3.5250e+00,\n",
       "        -2.7639e+00, -1.0230e+00, -4.8900e-01, -7.6287e-01,  6.1552e-01,\n",
       "        -1.9146e+00,  1.6701e+00, -2.7780e+00, -5.3034e+00, -2.6169e+00,\n",
       "         1.9044e+00,  4.2478e-01,  1.2126e+00,  3.4200e+00, -3.7740e+00,\n",
       "         3.8563e+00, -1.5441e+00, -5.5583e-01, -7.8609e-01,  7.3096e+00,\n",
       "        -3.7538e+00,  1.2796e+00, -1.4965e+00, -1.7970e+00,  1.3921e+00,\n",
       "        -5.4144e-01,  2.9503e+00, -4.3954e+00, -3.0116e+00, -1.0449e+00,\n",
       "        -2.5312e+00, -2.3410e+00,  1.6775e+00, -6.8062e+00,  1.6418e-01,\n",
       "         1.3007e-01,  4.8345e+00, -2.6272e-01,  1.1821e+00, -1.4113e+00,\n",
       "        -3.1120e-01, -3.0419e+00, -1.4450e+00, -3.4611e+00, -2.7980e+00,\n",
       "        -1.2548e+00,  3.7777e+00, -3.2552e+00, -5.3090e+00, -1.0525e+00,\n",
       "        -5.7262e-01,  1.4835e+00, -9.2114e-01,  2.3741e+00, -1.3843e+00,\n",
       "        -3.1265e+00,  1.4602e+00, -1.9525e+00, -2.4328e+00, -7.3652e+00,\n",
       "         2.8243e+00, -2.0114e+00,  6.1954e-01, -2.0169e+00,  4.1281e+00,\n",
       "        -2.7711e+00,  2.4468e+00, -1.8350e+00, -3.6264e+00, -3.4092e+00,\n",
       "        -2.6713e+00, -6.0130e+00, -6.5529e-02,  3.6684e+00, -3.3946e+00,\n",
       "        -1.1256e+00, -1.0729e+00, -3.3732e+00, -6.8511e-03, -5.3495e+00,\n",
       "         4.8809e+00, -7.8847e-01, -2.9404e-01, -4.4445e+00, -3.2157e+00,\n",
       "         6.6297e-01,  2.0787e+00, -1.3072e+00, -2.5153e+00,  2.8653e-01,\n",
       "        -1.0615e+00,  5.0795e+00,  2.8283e+00,  2.7250e+00,  3.3506e+00,\n",
       "         1.4338e+00,  1.6771e+00, -3.2674e+00,  2.8943e+00,  1.3369e+00,\n",
       "        -3.5974e+00,  1.0898e+00, -3.8169e+00,  2.4120e+00, -1.3490e+00,\n",
       "        -9.4113e-01,  8.0637e-01, -5.8078e+00, -3.7345e+00, -7.1524e-01,\n",
       "        -1.6587e+00,  6.1579e-02, -6.0362e+00,  2.2905e+00, -1.4526e+00,\n",
       "        -7.2179e-01,  5.2043e-01, -2.3966e+00,  6.8955e+00,  3.3183e+00,\n",
       "        -3.0300e+00,  4.2568e+00,  3.3432e+00,  4.7395e+00,  5.1314e+00,\n",
       "         4.6595e+00, -1.3867e+00,  1.2076e+00,  4.0511e-01, -3.3309e+00])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_idx = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -8.6872,  -8.6604,  -8.6337,  ...,  -8.5176,  -7.6843,  -5.3905],\n",
       "         [ -6.4908,  -6.3169,  -6.4961,  ...,  -6.1162,  -6.0905,  -5.9012],\n",
       "         [-13.3816, -14.1228, -13.6414,  ..., -12.2075, -10.2132,  -8.8761],\n",
       "         ...,\n",
       "         [ -6.2822,  -6.5075,  -6.6013,  ...,  -5.5398,  -5.3947,  -8.0459],\n",
       "         [-13.7735, -13.7491, -13.9186,  ..., -12.3411, -12.6793,  -9.6002],\n",
       "         [-16.1311, -16.3270, -16.3317,  ..., -16.5506, -14.1881,  -9.2726]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

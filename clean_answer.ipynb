{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util.util import *\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class JsonDataset:\n",
    "    def __init__(self, dataset_file):\n",
    "        self.dataset_file = dataset_file\n",
    "        self.dataset = load_json(self.dataset_file)\n",
    "\n",
    "    def json_to_plain(self, remove_notfound=False, stp=\"no-ent\", include_q_cands=False):\n",
    "        \"\"\"\n",
    "        :param remove_notfound: replace the truth answer by an equivalent answer (UMLS) found in the document \n",
    "        :param include_q_cands: whether to include entities in query in list of candidate answers\n",
    "        :param stp: no-ent | ent; whether to mark entities in passage; if ent, a multiword entity is treated as 1 token\n",
    "        :return: {\"id\": \"\",\n",
    "                  \"p\": \"\",\n",
    "                  \"q\", \"\",\n",
    "                  \"a\", \"\",\n",
    "                  \"c\", [\"\"]}\n",
    "        \"\"\"\n",
    "        for datum in self.dataset[DATA_KEY]:\n",
    "            for qa in datum[DOC_KEY][QAS_KEY]:\n",
    "                fields = {}\n",
    "                qa_txt_option = (\" \" + qa[QUERY_KEY]) if include_q_cands else \"\"\n",
    "                #cand = [w for w in to_entities(datum[DOC_KEY][TITLE_KEY] + \" \" +\n",
    "                #                               datum[DOC_KEY][CONTEXT_KEY] + qa_txt_option).lower().split() if w.startswith('@entity')]\n",
    "                cand = [w for w in to_entities(datum[DOC_KEY][TITLE_KEY] + \" \" +\n",
    "                                               datum[DOC_KEY][CONTEXT_KEY]).lower().split() if w.startswith('@entity')]\n",
    "                cand_q = [w for w in to_entities(qa_txt_option).lower().split() if w.startswith('@entity')]\n",
    "                if stp == \"no-ent\":\n",
    "                    c = {ent_to_plain(e) for e in set(cand)}\n",
    "                    a = \"\"\n",
    "                    for ans in qa[ANS_KEY]:\n",
    "                        if ans[ORIG_KEY] == \"dataset\":\n",
    "                            a = ans[TXT_KEY].lower()\n",
    "                    if remove_notfound:\n",
    "                        if a not in c:\n",
    "                            found_umls = False\n",
    "                            for ans in qa[ANS_KEY]:\n",
    "                                if ans[ORIG_KEY] == \"UMLS\":\n",
    "                                    umls_answer = ans[TXT_KEY].lower()\n",
    "                                    if umls_answer in c:\n",
    "                                        found_umls = True\n",
    "                                        a = umls_answer\n",
    "                            if not found_umls:\n",
    "                                continue\n",
    "                    fields[\"c\"] = list(c)\n",
    "                    assert a\n",
    "                    fields[\"a\"] = a\n",
    "                    document = remove_entity_marks(datum[DOC_KEY][TITLE_KEY] + \" \" + datum[DOC_KEY][CONTEXT_KEY]).replace(\n",
    "                        \"\\n\", \" \").lower()\n",
    "                    fields[\"p\"] = document\n",
    "                    fields[\"q\"] = remove_entity_marks(qa[QUERY_KEY]).replace(\"\\n\", \" \").lower()\n",
    "                        \n",
    "                elif stp == \"ent\":\n",
    "                    c = set(cand)\n",
    "                    c_q = set(cand_q)\n",
    "                    a = \"\"\n",
    "                    for ans in qa[ANS_KEY]:\n",
    "                        if ans[ORIG_KEY] == \"dataset\":\n",
    "                            a = plain_to_ent(ans[TXT_KEY].lower())\n",
    "                    if remove_notfound:\n",
    "                        if a not in c:\n",
    "                            found_umls = False\n",
    "                            for ans in qa[ANS_KEY]:\n",
    "                                if ans[ORIG_KEY] == \"UMLS\":\n",
    "                                    umls_answer = plain_to_ent(ans[TXT_KEY].lower())\n",
    "                                    if umls_answer in c:\n",
    "                                        found_umls = True\n",
    "                                        a = umls_answer\n",
    "                            if not found_umls:\n",
    "                                continue\n",
    "                    fields[\"c\"] = list(c) + list(c_q)\n",
    "                    assert a\n",
    "                    fields[\"a\"] = a\n",
    "                    document = to_entities(datum[DOC_KEY][TITLE_KEY] + \" \" + datum[DOC_KEY][CONTEXT_KEY]).replace(\n",
    "                        \"\\n\", \" \").lower()\n",
    "                    fields[\"p\"] = document\n",
    "                    fields[\"q\"] = to_entities(qa[QUERY_KEY]).replace(\"\\n\", \" \").lower()\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "                fields[\"id\"] = qa[ID_KEY]\n",
    "\n",
    "                yield fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"/data/medg/misc/phuongpm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# traindata = JsonDataset(filename + \"train1.0.json\").json_to_plain(remove_notfound=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devdata = JsonDataset(filename + \"dev1.0.json\").json_to_plain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "found_doc_ans = 0\n",
    "total = 0\n",
    "for d in devdata:\n",
    "    total += 1\n",
    "    if d[\"a\"] in d[\"p\"]:\n",
    "        found_doc_ans += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6391"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3888"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_doc_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
